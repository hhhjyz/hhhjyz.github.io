hhhjyz: 在实现目录、表和索引元信息的持久化后，你需要在src/include/catalog/catalog.h
和src/catalog/catalog.cpp中实现整个CatalogManager类。CatalogManager类应具备维护和持久化数据库中所有表和索引的信息。CatalogManager能够在数据库实例（DBStorageEngine）初次创建时（init = true）初始化元数据；并在后续重新打开数据库实例时，从数据库文件中加载所有的表和索引信息，构建TableInfo和IndexInfo信息置于内存中。此外，CatalogManager类还需要对上层模块提供对指定数据表的操作方式，如CreateTable、GetTable、GetTables、DropTable、GetTableIndexes；对上层模块提供对指定索引的操作方式，如CreateIndex、GetIndex、DropIndex。
      Note: 完成这部分时，需要注意对象内存的管理问题。我们在申请每一块内存的时候，都需要思考在什么时候进行释放。比如Schema类中，有深拷贝、浅拷贝函数，并且注释里写了什么时候该用深拷贝。如果没有正确使用，那么测试用例中shared_ptr会发生二次析构的报错。
Note: 在目前这种架构设计下，Catalog和实际数据存放在同一个数据库文件中。这使得Catalog Manager既依赖于Disk Manager 、Buffer Pool Manager，又为Record Manager、Index Manager、Executor(甚至Parser)提供接口支持，从而导致整个MiniSQL项目的内聚度相当地高。为此，一种妥协式的方案是：Catalog Manager不依赖于Disk Manager和Buffer Pool Manager，而是存放在独立的文件中，通过持久化手段直接落盘，但这种做法同样存在缺点，即Catalog的信息完全不受事务管理控制，存在一致性和可恢复性的问题。同学们可以根据实际需要自行选择Catalog Manager的实现方式。


请在catalog.cpp中进行实现
请分析各个todo的函数应该怎么实现

GitHub Copilot: 好的，我们来分析一下 `CatalogManager` 类中各个函数的实现思路，并给出 `catalog.cpp` 的实现框架。

**核心职责:**

*   **元数据管理:** 维护数据库中所有表 (`TableInfo`) 和索引 (`IndexInfo`) 的元数据。
*   **持久化:** 在数据库启动时加载元数据，在关闭或必要时将元数据持久化到磁盘（通过 `BufferPoolManager`）。
*   **接口提供:** 为上层模块（如查询执行器）提供创建、获取、删除表和索引的接口。

**实现分析:**

1.  **`CatalogManager::CatalogManager(..., bool init)` (构造函数)**
    *   **`init = true` (首次创建):**
        *   调用 `buffer_pool_manager_->NewPage()` 为 Catalog 元数据分配一个新页面 (通常是 `CATALOG_META_PAGE_ID`，即 0)。
        *   获取此页面。
        *   创建新的 `CatalogMeta` 对象 (`catalog_meta_ = CatalogMeta::NewInstance();`)。
        *   初始化 `next_table_id_` 和 `next_index_id_` (通常为 0)。
        *   将新的 `catalog_meta_` 序列化到获取到的页面数据区。
        *   标记页面为脏页并 Unpin。
    *   **`init = false` (重新打开):**
        *   调用 `buffer_pool_manager_->FetchPage(CATALOG_META_PAGE_ID)` 获取 Catalog 元数据页面。
        *   从页面数据区反序列化 `CatalogMeta` 对象 (`catalog_meta_ = CatalogMeta::DeserializeFrom(...)`)。
        *   Unpin 页面。
        *   遍历 `catalog_meta_->table_meta_pages_` 和 `catalog_meta_->index_meta_pages_`，对每个条目调用 `LoadTable` 和 `LoadIndex` 来加载表和索引信息到内存中的 `tables_` 和 `indexes_` 等 map 中。
        *   根据加载的 `catalog_meta_` 设置 `next_table_id_` 和 `next_index_id_`。
    *   **通用:** 保存传入的 `buffer_pool_manager_`, `lock_manager_`, `log_manager_` 指针。初始化内存中的 `table_names_`, `tables_`, `index_names_`, `indexes_` map。

2.  **`CatalogManager::~CatalogManager()` (析构函数)**
    *   调用 `FlushCatalogMetaPage()` 确保最新的 Catalog 元数据被写入磁盘。
    *   释放 `catalog_meta_`。
    *   遍历 `tables_` map，删除所有 `TableInfo*` 对象。
    *   遍历 `indexes_` map，删除所有 `IndexInfo*` 对象。

3.  **`CatalogManager::CreateTable(...)`**
    *   检查 `table_names_` 中是否已存在同名表，若存在则返回 `DB_TABLE_ALREADY_EXIST`。
    *   获取新的 `table_id = next_table_id_.fetch_add(1)`。
    *   调用 `TableHeap::Create(...)` 创建表的堆存储结构，获取其根页面 ID (`root_page_id`)。
    *   调用 `TableMetadata::Create(...)` 创建表的元数据对象。**注意:** 这里需要传入 `schema` 的副本或确保 `TableMetadata` 正确管理其生命周期（根据 Note，可能需要深拷贝）。
    *   为表元数据分配新页面 (`buffer_pool_manager_->NewPage()`)，获取 `table_meta_page_id`。
    *   获取该页面，将 `TableMetadata` 序列化写入，标记为脏页并 Unpin。
    *   将 `{table_id, table_meta_page_id}` 添加到 `catalog_meta_->table_meta_pages_`。
    *   调用 `FlushCatalogMetaPage()` 持久化 Catalog 元数据更新。
    *   创建 `TableInfo` 对象，并用 `table_metadata` 和 `table_heap` 初始化 (`table_info->Init(...)`)。
    *   将新表信息添加到内存 map: `table_names_[table_name] = table_id` 和 `tables_[table_id] = table_info`。
    *   返回 `DB_SUCCESS`。

4.  **`CatalogManager::GetTable(const std::string &table_name, ...)`**
    *   在 `table_names_` 中查找 `table_name`。若未找到，返回 `DB_TABLE_NOT_EXIST`。
    *   获取 `table_id`。
    *   调用内部辅助函数 `GetTable(table_id, table_info)`。

5.  **`CatalogManager::GetTable(const table_id_t table_id, ...)` (内部辅助)**
    *   在 `tables_` map 中查找 `table_id`。
    *   若找到，将对应的 `TableInfo*` 赋值给输出参数 `table_info`，返回 `DB_SUCCESS`。
    *   若未找到，返回 `DB_TABLE_NOT_EXIST`。

6.  **`CatalogManager::GetTables(...) const`**
    *   清空传入的 `tables` vector。
    *   遍历 `tables_` map，将每个 `TableInfo*` 添加到 `tables` vector 中。
    *   返回 `DB_SUCCESS`。

7.  **`CatalogManager::CreateIndex(...)`**
    *   调用 `GetTable(table_name, ...)` 检查表是否存在，获取 `TableInfo*`。若不存在，返回 `DB_TABLE_NOT_EXIST`。
    *   检查 `index_names_[table_name]` 中是否已存在同名索引，若存在则返回 `DB_INDEX_ALREADY_EXIST`。
    *   验证 `index_keys` 中的列名是否存在于表的 `Schema` 中，并获取对应的列索引 `key_map`。若有列不存在，返回 `DB_COLUMN_NAME_NOT_EXIST`。
    *   获取新的 `index_id = next_index_id_.fetch_add(1)`。
    *   调用 `IndexMetadata::Create(...)` 创建索引元数据。
    *   为索引元数据分配新页面，获取 `index_meta_page_id`。
    *   获取该页面，将 `IndexMetadata` 序列化写入，标记为脏页并 Unpin。
    *   将 `{index_id, index_meta_page_id}` 添加到 `catalog_meta_->index_meta_pages_`。
    *   调用 `FlushCatalogMetaPage()` 持久化 Catalog 元数据更新。
    *   创建 `IndexInfo` 对象，并用 `index_metadata`, `table_info`, `buffer_pool_manager` 初始化 (`index_info->Init(...)`)。这会创建实际的索引结构（如 B+ 树）。
    *   将新索引信息添加到内存 map: `index_names_[table_name][index_name] = index_id` 和 `indexes_[index_id] = index_info`。
    *   **重要:** 遍历表中的现有数据 (`table_info->GetTableHeap()`)，并将条目插入到新创建的索引 (`index_info->GetIndex()`) 中。
    *   返回 `DB_SUCCESS`。

8.  **`CatalogManager::GetIndex(...) const`**
    *   检查 `index_names_` 中是否存在 `table_name`。
    *   检查 `index_names_[table_name]` 中是否存在 `index_name`。
    *   若都存在，获取 `index_id`。
    *   在 `indexes_` map 中查找 `index_id`，获取 `IndexInfo*` 并赋值给输出参数 `index_info`。
    *   若任一检查失败或未在 `indexes_` 中找到，返回 `DB_INDEX_NOT_FOUND`。
    *   成功找到则返回 `DB_SUCCESS`。

9.  **`CatalogManager::GetTableIndexes(...) const`**
    *   清空传入的 `indexes` vector。
    *   检查 `index_names_` 中是否存在 `table_name`。若不存在，直接返回 `DB_SUCCESS`。
    *   获取 `index_names_[table_name]` (这是一个 `index_name` 到 `index_id` 的 map)。
    *   遍历这个内部 map，对每个 `index_id`，在 `indexes_` map 中查找对应的 `IndexInfo*`，并将其添加到 `indexes` vector 中。
    *   返回 `DB_SUCCESS`。

10. **`CatalogManager::DropTable(const std::string &table_name)`**
    *   调用 `GetTable(table_name, ...)` 检查表是否存在，获取 `table_id`。若不存在，返回 `DB_TABLE_NOT_EXIST`。
    *   调用内部辅助函数 `DropTable(table_id)`。

11. **`CatalogManager::DropTable(table_id_t table_id)` (内部辅助)**
    *   调用 `GetTable(table_id, ...)` 获取 `TableInfo*`。
    *   获取 `table_name`。
    *   获取 `table_meta_page_id` 从 `catalog_meta_->table_meta_pages_`。
    *   调用 `GetTableIndexes(table_name, ...)` 获取该表的所有 `IndexInfo*`。
    *   遍历这些 `IndexInfo*`，对每个索引调用 `DropIndex(table_name, index_info->GetIndexName())`。
    *   从 `catalog_meta_->table_meta_pages_` 中移除该表的条目。
    *   调用 `buffer_pool_manager_->DeletePage(table_meta_page_id)` 删除表元数据页面。
    *   调用 `table_info->GetTableHeap()->DeleteTable()` 删除表的所有数据页面。
    *   调用 `FlushCatalogMetaPage()` 持久化 Catalog 元数据更新。
    *   从内存 map 中移除表信息: `table_names_.erase(table_name)` 和 `tables_.erase(table_id)`。
    *   **重要:** `delete table_info` 释放 `TableInfo` 及其拥有的 `TableMetadata` 和 `TableHeap`。
    *   返回 `DB_SUCCESS`。

12. **`CatalogManager::DropIndex(const std::string &table_name, const std::string &index_name)`**
    *   检查 `index_names_` 和 `index_names_[table_name]` 是否存在 `index_name`。若不存在，返回 `DB_INDEX_NOT_FOUND`。
    *   获取 `index_id`。
    *   在 `indexes_` map 中查找 `index_id` 获取 `IndexInfo*`。
    *   获取 `index_meta_page_id` 从 `catalog_meta_->index_meta_pages_`。
    *   从 `catalog_meta_->index_meta_pages_` 中移除该索引的条目。
    *   调用 `buffer_pool_manager_->DeletePage(index_meta_page_id)` 删除索引元数据页面。
    *   调用 `FlushCatalogMetaPage()` 持久化 Catalog 元数据更新。
    *   从内存 map 中移除索引信息: `index_names_[table_name].erase(index_name)` (如果 `index_names_[table_name]` 为空则 `index_names_.erase(table_name)`) 和 `indexes_.erase(index_id)`。
    *   **重要:** `delete index_info` 释放 `IndexInfo` 及其拥有的 `IndexMetadata` 和 `Index` 结构。
    *   返回 `DB_SUCCESS`。

13. **`CatalogManager::FlushCatalogMetaPage() const`**
    *   获取 Catalog 元数据页面 (`buffer_pool_manager_->FetchPage(CATALOG_META_PAGE_ID)`)。
    *   将 `catalog_meta_` 序列化到页面数据区。
    *   调用 `buffer_pool_manager_->FlushPage(CATALOG_META_PAGE_ID)` 将页面写入磁盘。
    *   Unpin 页面 (不需要标记为脏页，因为刚 Flush 过)。
    *   返回 `DB_SUCCESS`。

14. **`CatalogManager::LoadTable(...)`**
    *   获取表元数据页面 (`buffer_pool_manager_->FetchPage(page_id)`)。
    *   反序列化 `TableMetadata`。
    *   Unpin 页面。
    *   使用 `TableMetadata` 中的 `root_page_id` 和 `schema` 创建 `TableHeap`。
    *   创建 `TableInfo` 并用 `TableMetadata` 和 `TableHeap` 初始化。
    *   将加载的 `TableInfo` 添加到 `table_names_` 和 `tables_` map 中。
    *   返回 `DB_SUCCESS`。

15. **`CatalogManager::LoadIndex(...)`**
    *   获取索引元数据页面 (`buffer_pool_manager_->FetchPage(page_id)`)。
    *   反序列化 `IndexMetadata`。
    *   Unpin 页面。
    *   从 `IndexMetadata` 获取 `table_id`。
    *   调用 `GetTable(table_id, ...)` 获取对应的 `TableInfo*`。
    *   创建 `IndexInfo` 并用 `IndexMetadata`, `TableInfo`, `buffer_pool_manager` 初始化。
    *   将加载的 `IndexInfo` 添加到 `index_names_` 和 `indexes_` map 中。
    *   返回 `DB_SUCCESS`。

**`catalog.cpp` 实现框架 (部分示例):**

```cpp
#include "catalog/catalog.h"
#include "common/config.h"
#include "common/macros.h"
#include "storage/table_heap.h"
#include "catalog/table.h"
#include "catalog/indexes.h"
#include "page/table_page.h" // Might be needed for TableHeap::DeleteTable

CatalogManager::CatalogManager(BufferPoolManager *buffer_pool_manager, LockManager *lock_manager,
                               LogManager *log_manager, bool init)
    : buffer_pool_manager_(buffer_pool_manager),
      lock_manager_(lock_manager),
      log_manager_(log_manager),
      catalog_meta_(nullptr),
      next_table_id_(0),
      next_index_id_(0) {
    if (init) {
        // Allocate page for catalog meta
        page_id_t catalog_meta_page_id = INVALID_PAGE_ID;
        Page *catalog_page = buffer_pool_manager_->NewPage(catalog_meta_page_id);
        ASSERT(catalog_page != nullptr && catalog_meta_page_id == CATALOG_META_PAGE_ID, "Failed to create catalog meta page.");

        // Create and serialize new catalog meta
        catalog_meta_ = CatalogMeta::NewInstance();
        catalog_meta_->SerializeTo(catalog_page->GetData());

        // Init next ids
        next_table_id_.store(0);
        next_index_id_.store(0);

        // Unpin and mark dirty
        buffer_pool_manager_->UnpinPage(catalog_meta_page_id, true);
        // Flush immediately to ensure persistence on creation
        buffer_pool_manager_->FlushPage(catalog_meta_page_id);

    } else {
        // Fetch existing catalog meta page
        Page *catalog_page = buffer_pool_manager_->FetchPage(CATALOG_META_PAGE_ID);
        ASSERT(catalog_page != nullptr, "Failed to fetch catalog meta page.");

        // Deserialize catalog meta
        catalog_meta_ = CatalogMeta::DeserializeFrom(catalog_page->GetData());
        ASSERT(catalog_meta_ != nullptr, "Failed to deserialize catalog meta.");

        // Unpin page
        buffer_pool_manager_->UnpinPage(CATALOG_META_PAGE_ID, false);

        // Load tables
        for (const auto &pair : catalog_meta_->table_meta_pages_) {
            LoadTable(pair.first, pair.second);
        }

        // Load indexes
        for (const auto &pair : catalog_meta_->index_meta_pages_) {
            LoadIndex(pair.first, pair.second);
        }

        // Set next ids based on loaded meta
        next_table_id_.store(catalog_meta_->GetNextTableId());
        next_index_id_.store(catalog_meta_->GetNextIndexId());
    }
}

CatalogManager::~CatalogManager() {
    // Persist catalog meta before exiting
    FlushCatalogMetaPage();

    // Clean up heap-allocated objects
    delete catalog_meta_;
    for (auto &pair : tables_) {
        delete pair.second; // Deletes TableInfo, which deletes TableMetadata and TableHeap
    }
    tables_.clear();
    table_names_.clear();

    for (auto &pair : indexes_) {
        delete pair.second; // Deletes IndexInfo, which deletes IndexMetadata and Index
    }
    indexes_.clear();
    index_names_.clear();
}

dberr_t CatalogManager::CreateTable(const std::string &table_name, TableSchema *schema, Txn *txn,
                                    TableInfo *&table_info) {
    // Check if table already exists
    if (table_names_.count(table_name)) {
        return DB_TABLE_ALREADY_EXIST;
    }

    // Allocate table id
    table_id_t table_id = next_table_id_.fetch_add(1);

    // Create TableHeap (allocates first page)
    // Note: Schema ownership needs careful handling here based on TableHeap::Create implementation
    TableHeap *table_heap = TableHeap::Create(buffer_pool_manager_, schema, txn, log_manager_, lock_manager_);
    if (table_heap == nullptr) {
        // Rollback table id allocation if needed, though atomic fetch_add is hard to roll back directly
        // Maybe decrement, but concurrent access could be an issue. Better to let IDs have gaps.
        return DB_FAILED; // Indicate failure
    }
    page_id_t first_page_id = table_heap->GetFirstPageId();

    // Create TableMetadata (takes ownership or copies schema)
    // Ensure schema passed here is correctly managed (e.g., deep copy if needed)
    TableMetadata *table_meta = TableMetadata::Create(table_id, table_name, first_page_id, schema);
     if (table_meta == nullptr) {
        // Clean up table_heap if metadata creation fails
        table_heap->DeleteTable(); // Assuming this cleans up the heap pages
        delete table_heap;
        return DB_FAILED;
    }


    // Allocate and write table metadata page
    page_id_t table_meta_page_id = INVALID_PAGE_ID;
    Page *meta_page = buffer_pool_manager_->NewPage(table_meta_page_id);
     if (meta_page == nullptr) {
        // Clean up table_heap and table_meta
        table_heap->DeleteTable();
        delete table_heap;
        delete table_meta; // TableMetadata destructor should handle schema if owned
        return DB_FAILED;
    }
    table_meta->SerializeTo(meta_page->GetData());
    buffer_pool_manager_->UnpinPage(table_meta_page_id, true);

    // Update catalog meta
    catalog_meta_->table_meta_pages_[table_id] = table_meta_page_id;
    if (FlushCatalogMetaPage() != DB_SUCCESS) {
         // Clean up everything if flush fails
        buffer_pool_manager_->DeletePage(table_meta_page_id);
        table_heap->DeleteTable();
        delete table_heap;
        delete table_meta;
        catalog_meta_->table_meta_pages_.erase(table_id); // Revert catalog meta change
        // Attempt to flush again or handle error
        return DB_FAILED;
    }


    // Create and init TableInfo
    table_info = TableInfo::Create();
    table_info->Init(table_meta, table_heap); // TableInfo takes ownership

    // Update in-memory maps
    table_names_[table_name] = table_id;
    tables_[table_id] = table_info;

    return DB_SUCCESS;
}

dberr_t CatalogManager::GetTable(const std::string &table_name, TableInfo *&table_info) {
    auto it_name = table_names_.find(table_name);
    if (it_name == table_names_.end()) {
        return DB_TABLE_NOT_EXIST;
    }
    return GetTable(it_name->second, table_info);
}


dberr_t CatalogManager::GetTable(const table_id_t table_id, TableInfo *&table_info) {
     auto it_table = tables_.find(table_id);
    if (it_table == tables_.end()) {
        // This might indicate an inconsistency if called internally after checking table_names_
        // Or could happen if called directly with an invalid ID
        return DB_TABLE_NOT_EXIST;
    }
    table_info = it_table->second;
    return DB_SUCCESS;
}


dberr_t CatalogManager::GetTables(std::vector<TableInfo *> &tables) const {
    tables.clear();
    for (const auto &pair : tables_) {
        tables.push_back(pair.second);
    }
    return DB_SUCCESS;
}


dberr_t CatalogManager::CreateIndex(const std::string &table_name, const std::string &index_name,
                                    const std::vector<std::string> &index_keys, Txn *txn, IndexInfo *&index_info,
                                    const string &index_type) {
    // 1. Get TableInfo
    TableInfo *table_info_ptr = nullptr;
    dberr_t err = GetTable(table_name, table_info_ptr);
    if (err != DB_SUCCESS) {
        return err;
    }
    table_id_t table_id = table_info_ptr->GetTableId();
    Schema *table_schema = table_info_ptr->GetSchema();

    // 2. Check if index name already exists for this table
    if (index_names_.count(table_name) && index_names_[table_name].count(index_name)) {
        return DB_INDEX_ALREADY_EXIST;
    }

    // 3. Validate index keys and get key_map
    std::vector<uint32_t> key_map;
    key_map.reserve(index_keys.size());
    for (const std::string &key_name : index_keys) {
        uint32_t column_index;
        if (table_schema->GetColumnIndex(key_name, column_index) != DB_SUCCESS) {
            return DB_COLUMN_NAME_NOT_EXIST;
        }
        key_map.push_back(column_index);
    }

    // 4. Allocate index id
    index_id_t index_id = next_index_id_.fetch_add(1);

    // 5. Create IndexMetadata
    IndexMetadata *index_meta = IndexMetadata::Create(index_id, index_name, table_id, key_map);
     if (index_meta == nullptr) {
        return DB_FAILED;
    }

    // 6. Allocate and write index metadata page
    page_id_t index_meta_page_id = INVALID_PAGE_ID;
    Page *meta_page = buffer_pool_manager_->NewPage(index_meta_page_id);
    if (meta_page == nullptr) {
        delete index_meta;
        return DB_FAILED;
    }
    index_meta->SerializeTo(meta_page->GetData());
    buffer_pool_manager_->UnpinPage(index_meta_page_id, true);


    // 7. Update catalog meta
    catalog_meta_->index_meta_pages_[index_id] = index_meta_page_id;
     if (FlushCatalogMetaPage() != DB_SUCCESS) {
        buffer_pool_manager_->DeletePage(index_meta_page_id);
        delete index_meta;
        catalog_meta_->index_meta_pages_.erase(index_id);
        return DB_FAILED;
    }


    // 8. Create and init IndexInfo (this creates the actual index structure)
    index_info = IndexInfo::Create();
    index_info->Init(index_meta, table_info_ptr, buffer_pool_manager_); // IndexInfo takes ownership of index_meta

    // 9. Update in-memory maps
    index_names_[table_name][index_name] = index_id;
    indexes_[index_id] = index_info;

    // 10. Populate the index with existing data (IMPORTANT and potentially complex)
    // This requires iterating through the table heap and inserting into the index.
    // This part is simplified here and needs proper implementation.
    TableHeap *table_heap = table_info_ptr->GetTableHeap();
    Index *bpt_index = index_info->GetIndex();
    for (auto it = table_heap->Begin(txn); it != table_heap->End(); ++it) {
        Row row = *it; // Get the current row
        // Create the index key from the row based on key_map
        Row index_key_row;
        row.GetKeyFromRow(table_schema, index_info->GetIndexKeySchema(), index_key_row);
        // Insert into the index
        dberr_t insert_err = bpt_index->InsertEntry(index_key_row, row.GetRowId(), txn);
        if (insert_err != DB_SUCCESS && insert_err != DB_KEY_ALREADY_EXIST) { // Allow duplicates unless it's a unique index
             // Handle insertion error - potentially rollback index creation?
             // For now, just log or return failure. A full rollback is complex.
             // Clean up partially created index state...
             DropIndex(table_name, index_name); // Attempt to clean up
             return DB_FAILED; // Indicate failure during population
        }
    }


    return DB_SUCCESS;
}


dberr_t CatalogManager::GetIndex(const std::string &table_name, const std::string &index_name,
                                 IndexInfo *&index_info) const {
    auto it_table = index_names_.find(table_name);
    if (it_table == index_names_.end()) {
        return DB_INDEX_NOT_FOUND;
    }
    auto it_index_name = it_table->second.find(index_name);
    if (it_index_name == it_table->second.end()) {
        return DB_INDEX_NOT_FOUND;
    }
    index_id_t index_id = it_index_name->second;

    auto it_index = indexes_.find(index_id);
    if (it_index == indexes_.end()) {
        // This indicates an inconsistency between index_names_ and indexes_
        return DB_INDEX_NOT_FOUND; // Or potentially DB_FAILED
    }
    index_info = it_index->second;
    return DB_SUCCESS;
}

dberr_t CatalogManager::GetTableIndexes(const std::string &table_name, std::vector<IndexInfo *> &indexes) const {
    indexes.clear();
    auto it_table = index_names_.find(table_name);
    if (it_table == index_names_.end()) {
        return DB_SUCCESS; // No indexes for this table
    }

    for (const auto &name_id_pair : it_table->second) {
        index_id_t index_id = name_id_pair.second;
        auto it_index = indexes_.find(index_id);
        if (it_index != indexes_.end()) {
            indexes.push_back(it_index->second);
        } else {
            // Inconsistency detected
            // LOG(WARNING) << "Inconsistency: Index ID " << index_id << " found in index_names_ but not in indexes_ for table " << table_name;
        }
    }
    return DB_SUCCESS;
}


dberr_t CatalogManager::DropTable(const std::string &table_name) {
     TableInfo *table_info_ptr = nullptr;
    dberr_t err = GetTable(table_name, table_info_ptr); // Use GetTable to find the table_id implicitly
    if (err != DB_SUCCESS) {
        return err; // Table doesn't exist
    }
    table_id_t table_id = table_info_ptr->GetTableId();
    return DropTable(table_id); // Call the internal helper
}


// Internal helper
dberr_t CatalogManager::DropTable(table_id_t table_id) {
    TableInfo *table_info_ptr = nullptr;
    if (GetTable(table_id, table_info_ptr) != DB_SUCCESS) {
         return DB_TABLE_NOT_EXIST; // Should not happen if called from public DropTable, but check anyway
    }
    std::string table_name = table_info_ptr->GetTableName();

    // 1. Drop all associated indexes first
    std::vector<IndexInfo *> table_indexes;
    GetTableIndexes(table_name, table_indexes); // Get list of indexes
    for (IndexInfo *index_info : table_indexes) {
        // Need to get index name to call DropIndex
        std::string index_name = index_info->GetIndexName();
        dberr_t drop_idx_err = DropIndex(table_name, index_name);
        if (drop_idx_err != DB_SUCCESS) {
            // Handle error during index drop - maybe log and continue, or abort?
             // LOG(ERROR) << "Failed to drop index " << index_name << " for table " << table_name;
             return drop_idx_err; // Abort dropping the table if index drop fails
        }
    }
     // At this point, index_names_[table_name] should be empty or table_name removed from index_names_

    // 2. Find and remove table metadata page id from catalog meta
    auto it_meta = catalog_meta_->table_meta_pages_.find(table_id);
    if (it_meta == catalog_meta_->table_meta_pages_.end()) {
        // Inconsistency
        // LOG(ERROR) << "Table ID " << table_id << " not found in catalog meta pages during drop.";
        // Still try to remove from memory maps
    } else {
        page_id_t table_meta_page_id = it_meta->second;
        catalog_meta_->table_meta_pages_.erase(it_meta); // Remove from map

        // 3. Delete the table metadata page
        buffer_pool_manager_->DeletePage(table_meta_page_id);
    }


    // 4. Delete the table heap data pages
    // TableInfo owns TableHeap, so deleting TableInfo will trigger TableHeap destructor if implemented correctly.
    // Alternatively, explicitly call a delete method if available.
    table_info_ptr->GetTableHeap()->DeleteTable(); // Assuming this method exists and deletes all heap pages


    // 5. Flush the updated catalog meta
    FlushCatalogMetaPage(); // Persist removal of table meta page entry


    // 6. Remove from in-memory maps
    table_names_.erase(table_name);
    auto it_table = tables_.find(table_id);
    if (it_table != tables_.end()) {
        delete it_table->second; // IMPORTANT: Delete the TableInfo object
        tables_.erase(it_table);
    }


    return DB_SUCCESS;
}


dberr_t CatalogManager::DropIndex(const std::string &table_name, const std::string &index_name) {
    // 1. Find index_id
     auto it_table = index_names_.find(table_name);
    if (it_table == index_names_.end()) {
        return DB_INDEX_NOT_FOUND;
    }
    auto it_index_name = it_table->second.find(index_name);
    if (it_index_name == it_table->second.end()) {
        return DB_INDEX_NOT_FOUND;
    }
    index_id_t index_id = it_index_name->second;

    // 2. Find IndexInfo*
    auto it_index = indexes_.find(index_id);
     if (it_index == indexes_.end()) {
        // Inconsistency
        // LOG(ERROR) << "Index ID " << index_id << " found in index_names_ but not in indexes_ during drop.";
        // Still try to remove from index_names_ and catalog meta
    }
     IndexInfo* index_info_ptr = (it_index != indexes_.end()) ? it_index->second : nullptr;


    // 3. Find and remove index metadata page id from catalog meta
    auto it_meta = catalog_meta_->index_meta_pages_.find(index_id);
    if (it_meta == catalog_meta_->index_meta_pages_.end()) {
         // Inconsistency
         // LOG(ERROR) << "Index ID " << index_id << " not found in catalog meta pages during drop.";
    } else {
        page_id_t index_meta_page_id = it_meta->second;
        catalog_meta_->index_meta_pages_.erase(it_meta); // Remove from map

        // 4. Delete the index metadata page
        buffer_pool_manager_->DeletePage(index_meta_page_id);
    }


    // 5. Flush the updated catalog meta
    FlushCatalogMetaPage(); // Persist removal of index meta page entry


    // 6. Remove from in-memory maps
    it_table->second.erase(it_index_name); // Remove index_name from inner map
    if (it_table->second.empty()) {
        index_names_.erase(it_table); // Remove table_name if no more indexes
    }

    if (it_index != indexes_.end()) {
        // IMPORTANT: Delete the IndexInfo object. Its destructor should handle deleting the IndexMetadata and the actual Index structure (e.g., B+ tree pages).
        delete index_info_ptr;
        indexes_.erase(it_index);
    }


    return DB_SUCCESS;
}


// Helper function to flush catalog meta page
dberr_t CatalogManager::FlushCatalogMetaPage() const {
    Page *catalog_page = buffer_pool_manager_->FetchPage(CATALOG_META_PAGE_ID);
    if (catalog_page == nullptr) {
        return DB_FAILED; // Cannot fetch page to flush
    }
    catalog_meta_->SerializeTo(catalog_page->GetData());
    // Flush the page to disk
    if (!buffer_pool_manager_->FlushPage(CATALOG_META_PAGE_ID)) {
         buffer_pool_manager_->UnpinPage(CATALOG_META_PAGE_ID, true); // Still need to unpin, mark dirty
        return DB_FAILED; // Flush failed
    }
    // Unpin the page, mark as not dirty since it's flushed
    buffer_pool_manager_->UnpinPage(CATALOG_META_PAGE_ID, false);
    return DB_SUCCESS;
}

// Helper function to load table info during startup
dberr_t CatalogManager::LoadTable(const table_id_t table_id, const page_id_t page_id) {
    Page *meta_page = buffer_pool_manager_->FetchPage(page_id);
    if (meta_page == nullptr) {
        return DB_FAILED;
    }
    TableMetadata *table_meta = nullptr;
    TableMetadata::DeserializeFrom(meta_page->GetData(), table_meta);
    buffer_pool_manager_->UnpinPage(page_id, false);

    if (table_meta == nullptr) {
        return DB_FAILED; // Deserialization failed
    }

    // Re-create TableHeap instance for the loaded table
    TableHeap *table_heap = TableHeap::Create(buffer_pool_manager_, table_meta->GetFirstPageId(),
                                            table_meta->GetSchema(), log_manager_, lock_manager_);
     if (table_heap == nullptr) {
        delete table_meta; // Clean up metadata if heap creation fails
        return DB_FAILED;
    }


    // Create and init TableInfo
    TableInfo *table_info = TableInfo::Create();
    table_info->Init(table_meta, table_heap); // Takes ownership

    // Add to in-memory maps
    table_names_[table_meta->GetTableName()] = table_id;
    tables_[table_id] = table_info;

    return DB_SUCCESS;
}

// Helper function to load index info during startup
dberr_t CatalogManager::LoadIndex(const index_id_t index_id, const page_id_t page_id) {
    Page *meta_page = buffer_pool_manager_->FetchPage(page_id);
     if (meta_page == nullptr) {
        return DB_FAILED;
    }
    IndexMetadata *index_meta = nullptr;
    IndexMetadata::DeserializeFrom(meta_page->GetData(), index_meta);
    buffer_pool_manager_->UnpinPage(page_id, false);

     if (index_meta == nullptr) {
        return DB_FAILED; // Deserialization failed
    }

    // Find the corresponding TableInfo
    TableInfo *table_info_ptr = nullptr;
    if (GetTable(index_meta->GetTableId(), table_info_ptr) != DB_SUCCESS) {
        delete index_meta; // Clean up metadata if table not found
        // LOG(ERROR) << "Table " << index_meta->GetTableId() << " not found for index " << index_meta->GetIndexName();
        return DB_TABLE_NOT_EXIST; // Or DB_FAILED for inconsistency
    }

    // Create and init IndexInfo
    IndexInfo *index_info = IndexInfo::Create();
    // Assuming Init handles creating the index structure (e.g., BPlusTreeIndex) based on metadata
    index_info->Init(index_meta, table_info_ptr, buffer_pool_manager_); // Takes ownership

    // Add to in-memory maps
    index_names_[table_info_ptr->GetTableName()][index_meta->GetIndexName()] = index_id;
    indexes_[index_id] = index_info;

    return DB_SUCCESS;
}

```

**重要注意事项:**

*   **错误处理和回滚:** 上述代码仅包含基本的错误检查。在实际实现中，创建表或索引失败时需要进行更完善的回滚操作（例如，如果 `FlushCatalogMetaPage` 失败，需要撤销内存中的更改并可能删除已分配的页面）。
*   **并发控制:** 对 `CatalogManager` 的并发访问需要通过锁（例如 `std::mutex`）来保护共享数据结构（`catalog_meta_`, `table_names_`, `tables_`, `index_names_`, `indexes_`, `next_table_id_`, `next_index_id_`）。每个公共方法都应在开始时获取锁，在结束时释放锁。
*   **内存管理:** 再次强调，需要仔细检查 `TableMetadata`, `IndexMetadata`, `TableInfo`, `IndexInfo`, `TableHeap`, `Schema` 等对象的生命周期和所有权转移，确保没有内存泄漏或二次释放。`TableInfo` 和 `IndexInfo` 的析构函数应正确释放它们拥有的资源。
*   **索引填充:** `CreateIndex` 中填充现有数据的部分需要健壮的实现，可能涉及事务和错误处理。
*   **依赖关系:** 确保所有必要的头文件都已包含。