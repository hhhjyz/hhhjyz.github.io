# 知识表达与推理

## 1 命题逻辑

**什么是逻辑**： 进行正确推理和充分论证的研究

早期符号主义人工智能（symbolic AI） 就是脱胎于逻辑推理

**逻辑关系的问题：**

- 从一个或若干前提出发，是否村子啊一个有效的论证或者推理来支持所得到的结论
- 逻辑和推理是人工智能的核心问题

**命题**：确定为真或为假的陈述句。命题总是具有一个“真值”。只有具有确定真值的陈述句才是命题，无法判断真或假的描述性句子不能作为命题。

!!! note 原子命题
    不包含其他命题作为其组成部分的命题，又称为简单命题

**复合命题**： 包含其他命题作为其组成部分的命题

<div align=center><img src="../assets/Chapter%202/file-20250227134104057.png" width=60%></div>

优先级：
<div align=center><img src="../assets/Chapter%202/file-20250227134340423.png" width=60%></div>

**逻辑等价**：具有相同的真假结果

!!! exmaple 
    <div align=center><img src="../assets/Chapter%202/file-20250227134649822.png" width=60%></div>


**命题逻辑推理的手段和方法：**

<div align=center><img src="../assets/Chapter%202/file-20250227135404503.png" width=60%></div>


**命题范式**
- 有限个简单合取式构成的析取式称为析取范式
- 有限个简单的析取式构成的合取式称为合取范式

!!! note
    - 一个析取范式是不成立的，当且仅当它的每个简单合取式都是不成立的
    - 一个合取范式是成立的，当且仅当它的每个简单析取式都是成立的
    - 任一命题公式都存在着与之等值的析取范式合合取范式（不唯一）


## 2 谓词逻辑

!!! note 为什么要从命题逻辑到谓词逻辑？

    在命题逻辑中，原子命题是最基本的单位。由原子命题出发，通过使用命题联结词，构成复合命题。命题    
    逻辑只能把复合命题分解为简单命题（即原子命题），无法对原子命题所包含的丰富语义（如个体、部分
    或全体等）进行刻画。因此，命题逻辑无法表达局部与整体、一般与个别的关系。

**谓词逻辑：** 刻画主体之间逻辑关系的方法

在谓词逻辑中，将原子命题进一步细化，分解出个体、谓词和量词，来表达个体与总体
的内在联系和数量关系，这就是谓词逻辑的研究内容。

- 个体：个体是指所研究领域中可以独立存在的具体或抽象的概念。

- 谓词：谓词是用来刻画个体属性或者描述个体之间关系存在性的元素，其值为真或为假

**全称量词和存在量词**

<div align=center><img src="../assets/Chapter%202/file-20250227143123766.png" width=60%></div>
**约束变元**： 在全称量词或存在量词的约束条件下的变量符号称为约束变元
**自由变元**： 不受全称量词或者存在量词约束的变量符号
e.g. $Q(x)$

<div align=center><img src="../assets/Chapter%202/file-20250227143429686.png" width=60%></div>

当公式中存在多个量词时，若多个量词都是全称量词或者都是存在量词，则

量词的位置可以互换；若多个量词中既有全称量词又有存在量词，则量词的位置不可
以随意互换

!!! example
    <div align=center><img src="assets/Chapter%202/file-20250306133300592.png" width=60%></div>

**项：** 项是描述对象的逻辑表达式，被递归地定义为：

(1) 常量符号和变量符号是项；

(2) 若$f(x_1,x_2,\cdots,x_n)$是n元函数符号，$t_1,t_2,\cdots,t_n$是项，则$f(t_1,t_2,\cdots,t_n)是项$

(3) 有限次数地使用上述规则产生的符号串是项

**原子谓词公式**:若$P(x_1,\cdots,x_n)$是n元谓词，$t_1,t_2,\cdots,t_n$是项，则称$P(t_1,t_2,\cdots,t_n)$是原子谓词公式

**合式公式**:合式公式是由逻辑联结词和原子公式构成的用于陈述事实的复杂语句，又称谓词公式，由

以下规则定义：
- 命题常项、命题变项、原子谓词公式是合式公式；
- 如果A是合式公式，则$\neg A$也是合式公式；
- 如果A和B是合式公式，则$A\wedge B,A\vee B,A\rightarrow B, A\leftarrow B ,A \leftrightarrow B$是合式公式
- <div align=center><img src="../assets/Chapter%202/file-20250227145119145.png"></div>

**谓词逻辑推理的手段和方法：**

<div align=center><img src="../assets/Chapter%202/file-20250227145213364.png" width=80%></div>


**专家系统：**

<div align=center><img src="../assets/Chapter%202/file-20250227151514233.png" width=60%></div>






## 3 知识图谱推理

知识图谱(knowledge graph)由有向图(directed graph)构成，被用来描述
现实世界中实体及实体之间的关系，是人工智能中进行知识表达的重
要方式。

知识图谱中存在连线的两个实体可以表示为形如$<left\_node,relation,right\_node>$的三元组，这种三元素也可以表示为一阶逻辑的形式

### 3.1 知识图谱推理： 归纳学习

<div align=center><img src="../assets/Chapter%202/file-20250306133827779.png" width =60%></dive>

**FOIL算法：**
在FOIL中，目标谓词是需要推断规则的结论，也称
为规则头。在给定推理结论后，FOIL算法学习得到
使得结论满足的前提条件，即目标谓词作为结论的推
理规则。

为了学习推理规则，需要构造目标谓词?的训练样例，训练样例包含正例集合$E^+$和反例集合$E^-$。

- 归纳逻辑程序设计（inductive logic programming，ILP）
    - ILP 是机器学习和逻辑程序设计交叉领域的研究内容
    - ILP 使用一阶谓词逻辑进行知识表示，通过修改和扩充逻辑表达式对现有知识进行归纳，完成推理内容
    - FOIL（first order inductive learner）算法是 ILP 的代表性方法，通过**序贯覆盖**学习推理规则
- 路径排序算法（path ranking algorithm，GRA）
    - 将实体之间的关联路径作为特征，来学习目标关系的分类器
    - 流程：
        1. 特征抽取：生成并选择路径特征集合。生成路径方法：随机游走（random walk）、BFS、DFS
        2. 特征计算：计算每个训练样例的特征值 $P(s\rightarrow t; \pi_j)$，表示从实体节点 $s$ 出发，通过关系路径 $\pi_j$ 达到实体节点 $t$ 的概率。或表示是否存在这样一条路径，或表示路径出现的频次频率
        3. 分类器训练：根据训练样例特征值，为目标关系训练分类器。训练后可用于推理两个实体间是否存在目标关系

??? note "FOIL 算法"
    - 算法内容
        - 输入：目标谓词 $P$，目标谓词 $P$ 的训练样例（正例集合 $E^+$ 和反例集合 $E^-$），以及其它背景知识样例
        - 输出：可得到目标谓词这一结论的推理规则
        - 过程：
            1. 将目标谓词作为所学习推理规则的结论
            2. 将其它谓词逐一作为**前提约束谓词**加入推理规则，计算所得到推理规则的 FOIL 信息增益值，选取可带来最大信息增益值的前提约束谓词加入原来的推理规则，得到新的推理规则，并将训练样例集合中与该推理规则不符的样例去掉
            3. 重复 b. 过程，知道所得到的推理规则不覆盖任何反例
    - 目标谓词是需要推断规则的结论，也称为规则头
    - 给定推理结论后，FOIL 算法学习得到使得结论满足的前提条件，即目标谓词作为结论的推理规则
    - FOIL 算法从一般到特殊，逐步添加目标谓词的前提约束谓词，直到所构成的推理规则不覆盖任何反例
    - 添加前提约束谓词后所得的推理规则的质量的好坏由信息增益值（information gain）作为评估标准，计算方法：
        
        $$
        \mathrm{FOIL\_Gain} = \widehat{m_+}\cdot\left(\log_2\frac{\widehat{m_+}}{\widehat{m_+}+\widehat{m_-}}-\log_2\frac{m_+}{m_++m_-}\right)
        $$

        - $\widehat{m_+}, \widehat{m_-}$ 是增加前提约束谓词后得到的新推理规则能覆盖的正例和反例数目
        - $m_+, m_-$ 是原推理规则覆盖的正例和反例数目
## 4 概率图推理

**刻画信息的不确定性**

贝叶斯网络 ： 用一个有向无 环 图（ directedacyclic graph）来表示，其用有向边来表示节点和节点之间的单向概率依赖。

马尔可夫网络：表示成一个无向图的网络结构，其用无向边来表示节点和节点之间的相互概率依赖

### 4.1 贝叶斯网络

满足局部马尔可夫性，即在给定一个节点的父节点的情况下，该父亲节点有条件的独立于它的非后代节点

<div align=center><img src=".../assets/Chapter%202/file-20250306140123464.png" width=70%></div>
图中给出的是条件变量，只和上一级有关


### 4.2 马尔可夫逻辑网络

![](assets/Chapter%202/file-20250306142819971.png)

$$P(X=x)=\frac{1}{Z}exp(\sum_i w_in_i(x))$$

## 5 因果推理


**辛普森悖论：**
在某些情况下，忽略潜在的第三个变量可能会改变已有 的结论，而我们常常会忽略这一因素

![](assets/Chapter%202/file-20250306150626378.png)


**两种理论框架：**

